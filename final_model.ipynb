{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import re\r\n",
    "\r\n",
    "def de_html(target):\r\n",
    "    filtered = re.sub(r'<.*>',' ',target)\r\n",
    "    return filtered\r\n",
    "\r\n",
    "def de_special_chars(target):\r\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#|$|@|&|%]',' ',target)\r\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\\\|/]',' ',cleaned)\r\n",
    "    return cleaned"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from nltk.stem import  SnowballStemmer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "stemmer = SnowballStemmer('english')\r\n",
    "stop_words = stopwords.words('english')\r\n",
    "\r\n",
    "def pipeline(target,pre_trained_model=None):\r\n",
    "    \"\"\"\r\n",
    "    target - A dataframe with the text under a column named 'Review'\r\n",
    "    pre_trained_model - A pre-trained word vectorizer model if already trained with train data.\r\n",
    "    \"\"\"\r\n",
    "    cleaned_data = []\r\n",
    "    for review in target['Review']:\r\n",
    "        cleaned_review = []\r\n",
    "        review = de_html(review)\r\n",
    "        review = de_special_chars(review)\r\n",
    "        for word in review.split():\r\n",
    "            if word.lower() not in stop_words:\r\n",
    "                if word.isalpha() and len(word) > 2:\r\n",
    "                    stemmed_word = stemmer.stem(word.lower())\r\n",
    "                    cleaned_review.append(stemmed_word)\r\n",
    "        cleaned_review = ' '.join(cleaned_review)\r\n",
    "        cleaned_data.append(cleaned_review)\r\n",
    "    \r\n",
    "    model = CountVectorizer(binary=True,ngram_range=(1,2))\r\n",
    "    if pre_trained_model:\r\n",
    "        model = pre_trained_model\r\n",
    "        results = model.transform(cleaned_data)\r\n",
    "    else:\r\n",
    "        model.fit(cleaned_data)\r\n",
    "        results = model.transform(cleaned_data)\r\n",
    "    \r\n",
    "    return results,model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Training the model:\r\n",
    "from sklearn.naive_bayes import BernoulliNB\r\n",
    "\r\n",
    "data = pd.read_csv('restaurant_reviews.tsv',sep='\\t')\r\n",
    "print(f'Original data: {data.shape}')\r\n",
    "cleaned_data,text_model = pipeline(data)\r\n",
    "print(f'cleaned_data : {cleaned_data.shape}')\r\n",
    "model = BernoulliNB(alpha=3)\r\n",
    "model.fit(cleaned_data,data['Liked'])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original data: (1000, 2)\n",
      "cleaned_data : (1000, 5495)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=3)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#Getting a review and making a prediction:\r\n",
    "test_review = input('Enter your review: ')\r\n",
    "print(f'The input review: {test_review}')\r\n",
    "test_review = pd.DataFrame(np.array([[test_review]]),columns=['Review'])\r\n",
    "cleaned_data,_ = pipeline(test_review,pre_trained_model=text_model)\r\n",
    "sentiment = model.predict(cleaned_data)\r\n",
    "sentiment = sentiment[0]\r\n",
    "if sentiment:\r\n",
    "    print('Thank you for your good feedback! Visit again!')\r\n",
    "else:\r\n",
    "    print('We apologize for your inconvenience. We\\'ll work on getting better')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The input review: Honeslty it didn't taste THAT fresh.)\n",
      "We apologize for your inconvenience. We'll work on getting better\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "4b785643ab0edb344e3d86bfa7c122367e835287c1d95d0d7983886da64befac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}